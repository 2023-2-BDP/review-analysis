{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "sjCdXJJTDZ7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gm9084C9Ote"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.rcParams['font.family'] = 'AppleGothic'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5Ca3cKV9Otl"
      },
      "outputs": [],
      "source": [
        "reviews = pd.read_csv('/content/drive/MyDrive/archive/coupang_reviews.csv', encoding='utf-8', sep='\\t')\n",
        "reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81ShEHjt9Otm"
      },
      "outputs": [],
      "source": [
        "reviews.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXD3ouz29Otn"
      },
      "outputs": [],
      "source": [
        "reviews['rating'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bt5Mi3Yf9Otn"
      },
      "outputs": [],
      "source": [
        "reviews[reviews['rating'] == '4']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jbrFenw9Oto",
        "outputId": "d1bc4034-0a88-4fc2-d400-05bed1985d63"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7917"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "len(reviews[~reviews['rating'].isin(['1', '2', '3', '4', '5'])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbYHtYR_9Oto"
      },
      "outputs": [],
      "source": [
        "# 평점이 1, 2, 3, 4, 5가 아닌 것들을 제거\n",
        "reviews = reviews[reviews['rating'].isin(['1', '2', '3', '4', '5'])]\n",
        "reviews['rating'] = reviews['rating'].astype('int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhSSoUbV9Otq"
      },
      "outputs": [],
      "source": [
        "# headline, review_content 모두 결측치 있는 row 제거\n",
        "reviews = reviews[reviews[['headline','review_content']].isnull().sum(axis=1) == 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "3zHAQM-V9Otq",
        "outputId": "01c34d99-c7d0-4388-bb54-cfea55c1b5cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [rating, headline, review_content]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1d21f699-64b2-4d49-af96-c4a8170dc8cd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>headline</th>\n",
              "      <th>review_content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d21f699-64b2-4d49-af96-c4a8170dc8cd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1d21f699-64b2-4d49-af96-c4a8170dc8cd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1d21f699-64b2-4d49-af96-c4a8170dc8cd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# headline, review_content 모두 내용이 없는 row\n",
        "reviews[reviews['headline'].str.contains('등록된 헤드라인이') & reviews['review_content'].str.contains('등록된 리뷰내용이')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWM26tJf9Otr"
      },
      "outputs": [],
      "source": [
        "reviews['rating'].value_counts().sort_index(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCRiYc4g9Ots"
      },
      "outputs": [],
      "source": [
        "# 평점 분포 확인\n",
        "\n",
        "x = [f\"{rating} ({count})\" for rating, count in reviews['rating'].value_counts().sort_index(ascending=False).items()]\n",
        "\n",
        "sns.barplot(x=x, y=reviews['rating'].value_counts().sort_index(ascending=False).values)\n",
        "# y축에 표시 없애기\n",
        "plt.title('평점 분포')\n",
        "plt.yticks([])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejPocZQN9Ots"
      },
      "outputs": [],
      "source": [
        "# '등록된 헤드라인이 없습니다' 포함한 headline 빈 문자열로 변경\n",
        "# '등록된 리뷰내용이 없습니다' 포함한 review_content 빈 문자열로 변경\n",
        "reviews['headline'] = np.where(reviews['headline'].str.contains('등록된 헤드라인이'), '', reviews['headline'])\n",
        "reviews['review_content'] = np.where(reviews['review_content'].str.contains('등록된 리뷰내용이'), '', reviews['review_content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cXLh85p9Ots"
      },
      "outputs": [],
      "source": [
        "# headline, review_content 공백을 기준으로 합치기\n",
        "reviews['content'] = reviews['headline'] + \" \" + reviews['review_content']\n",
        "reviews = reviews[['rating', 'content']].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZvpJKuf9Ott"
      },
      "outputs": [],
      "source": [
        "# 중복된 리뷰 제거\n",
        "print(reviews.duplicated(subset=['rating', 'content']).sum())\n",
        "print(len(reviews))\n",
        "reviews.drop_duplicates(subset=['rating', 'content'], keep='first', inplace=True)\n",
        "print(len(reviews))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-XyCVMf9Ott"
      },
      "outputs": [],
      "source": [
        "!pip install konlpy\n",
        "from konlpy.tag import Komoran, Okt, Kkma\n",
        "import re\n",
        "\n",
        "kkma = Kkma()\n",
        "komoran = Komoran()\n",
        "okt = Okt()\n",
        "\n",
        "# 한글과 공백을 제외하고 모두 제거\n",
        "def apply_regular_expression(text):\n",
        "    hangul = re.compile('[^ ㄱ-ㅣ 가-힣]')\n",
        "    result = hangul.sub('', text)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GA0XRMz9Ott"
      },
      "outputs": [],
      "source": [
        "s = apply_regular_expression(reviews.iloc[63]['content'])\n",
        "print(s)\n",
        "\n",
        "# morphs : 형태소 추출\n",
        "# nouns : 명사 추출\n",
        "\n",
        "# kkma -> 속도 너무 느림\n",
        "# komoran -> 속도 빠름, 하지만 명사를 너무 잘게 나눔 (ex. 배송 -> 배,송)\n",
        "# okt -> 속도 빠름, 명사 추출에 좋은 성능을 보임\n",
        "\n",
        "# 형태소 없이 명사만 추출해도 의미를 파악하는데 충분하다고 판단\n",
        "# print(kkma.morphs(s))\n",
        "# print(kkma.nouns(s))\n",
        "# print()\n",
        "# print(komoran.morphs(s))\n",
        "# print(komoran.nouns(s))\n",
        "# print()\n",
        "# print(okt.morphs(s))\n",
        "# print(okt.nouns(s))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIAGyM2L9Ott"
      },
      "outputs": [],
      "source": [
        "# 한글자로 된 단어는 의미가 없으므로 제거\n",
        "print([word for word in okt.nouns(s) if len(word) > 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSH_S1fw9Otu"
      },
      "outputs": [],
      "source": [
        "# 빈도 분석\n",
        "from collections import Counter\n",
        "\n",
        "counter = Counter([word for word in okt.nouns(s) if len(word) > 1])\n",
        "\n",
        "counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvuaKZ4e9Otu"
      },
      "outputs": [],
      "source": [
        "# 불용어 제거\n",
        "stopwords = pd.read_csv(\"https://raw.githubusercontent.com/yoonkt200/FastCampusDataset/master/korean_stopwords.txt\").values.tolist()\n",
        "print(len(stopwords))\n",
        "print(stopwords[:10])\n",
        "\n",
        "# 리뷰 데이터에 많이 포함된 불용어 추가\n",
        "stopwords.extend(['쿠팡', '리뷰'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTN979K19Otu"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def split_rating(rating):\n",
        "    if rating == 5:\n",
        "        return 1\n",
        "    if rating in [1,2,3]:\n",
        "        return 0\n",
        "    return -1\n",
        "\n",
        "reviews['sentiment'] = reviews['rating'].apply(split_rating)\n",
        "print(reviews['sentiment'].value_counts())\n",
        "\n",
        "reviews_sample_positive = reviews[reviews['sentiment'] == 1].sample(15000, random_state=1353)\n",
        "reviews_sample_negative = reviews[reviews['sentiment'] == 0].sample(15000, random_state=1353)\n",
        "reviews_sample = pd.concat([reviews_sample_positive, reviews_sample_negative]).reset_index(drop=True)\n",
        "print(reviews_sample['sentiment'].value_counts())\n",
        "print(reviews_sample.shape)\n",
        "\n",
        "train_x, temp_x, train_y, temp_y = train_test_split(reviews_sample['content'], reviews_sample['sentiment'], test_size=0.4, random_state=1353)\n",
        "test_x, valid_x, test_y, valid_y = train_test_split(temp_x, temp_y, test_size=0.5, random_state=1353)\n",
        "\n",
        "del temp_x, temp_y\n",
        "\n",
        "print(train_x.shape, train_y.shape)\n",
        "print(valid_x.shape, valid_y.shape)\n",
        "print(test_x.shape, test_y.shape)\n",
        "\n",
        "print(train_y.value_counts())\n",
        "print(valid_y.value_counts())\n",
        "print(test_y.value_counts())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ob1oibqv9Otu"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "def text_cleaning(text):\n",
        "    hangul = re.compile('[^ ㄱ-ㅣ 가-힣]')\n",
        "    result = hangul.sub('', text)\n",
        "    result = [word for word in okt.nouns(result) if len(word) > 1]\n",
        "    result = [word for word in result if not word in stopwords]\n",
        "    return result\n",
        "\n",
        "cv = CountVectorizer(tokenizer = lambda x: text_cleaning(x))\n",
        "cv.fit(train_x)\n",
        "x_train_cv = cv.transform(train_x)\n",
        "x_valid_cv = cv.transform(valid_x)\n",
        "x_test_cv = cv.transform(test_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFg8KAhL9Otv"
      },
      "outputs": [],
      "source": [
        "print(x_train_cv.toarray()) # 각 단어의 리뷰별 등장 횟수. row: 리뷰, column: 단어\n",
        "print(x_train_cv.shape)\n",
        "word_list = cv.get_feature_names_out() # 단어 리스트\n",
        "count_list:np.ndarray = x_train_cv.toarray().sum(axis=0) # 각 단어의 빈도 리스트\n",
        "print(len(word_list))\n",
        "print(len(count_list))\n",
        "print(word_list[count_list.argsort()[::-1]][:30]) # 빈도수가 높은 단어 30개\n",
        "print(dict(zip(word_list, count_list))) # 단어별 빈도수 Dictonary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKbT5ni19Otv"
      },
      "outputs": [],
      "source": [
        "# TF-IDF\n",
        "# TfidfVectorizer: 텍스트 데이터를 TF-IDF 행렬로 변환\n",
        "# TfidfTransformer: 기존에 계산된 TF (Term Frequency) 행렬을 TF-IDF 행렬로 변환\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "tfidf_transformer.fit(x_train_cv)\n",
        "x_train_tfidf = tfidf_transformer.transform(x_train_cv)\n",
        "x_valid_tfidf = tfidf_transformer.transform(x_valid_cv)\n",
        "x_test_tfidf = tfidf_transformer.transform(x_test_cv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqEDOV3V9Otv"
      },
      "outputs": [],
      "source": [
        "print(x_train_tfidf.shape,end='\\n\\n') # (리뷰 개수, 단어 종류 개수)\n",
        "print('BOW에서 단어의 중요도(0이 아닌 것만 출력)')\n",
        "print(x_train_cv[0],end='\\n\\n')\n",
        "print('TF-IDF에서 단어의 중요도(0이 아닌 것만 출력)')\n",
        "print(x_train_tfidf[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otMf9s2Z9Otv"
      },
      "outputs": [],
      "source": [
        "# 로지스틱 회귀\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "params = {'C': [1], 'max_iter': [100]}\n",
        "best_params = {}\n",
        "best_score = 0\n",
        "\n",
        "for C in params['C']:\n",
        "    for max_iter in params['max_iter']:\n",
        "        lr = LogisticRegression(C=C, max_iter=max_iter, random_state=1353)\n",
        "        lr.fit(x_train_tfidf, train_y)\n",
        "        pred_y = lr.predict(x_valid_tfidf)\n",
        "        score = accuracy_score(valid_y, pred_y)\n",
        "\n",
        "        print()\n",
        "        print(\"=\" * 30)\n",
        "        print(\">>>> accuracy-score: {}\".format(accuracy_score(valid_y, pred_y)))\n",
        "        print(\">>>> precision-score: {}\".format(precision_score(valid_y, pred_y)))\n",
        "        print(\">>>> recall-score: {}\".format(recall_score(valid_y, pred_y)))\n",
        "        print(\">>>> f1-score: {}\".format(f1_score(valid_y, pred_y)))\n",
        "        print()\n",
        "        print(\">>>> Params: {}\".format({ 'C': C, 'max_iter': max_iter}))\n",
        "        print(\"=\" * 30)\n",
        "        print()\n",
        "\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_params['C'] = C\n",
        "            best_params['max_iter'] = max_iter\n",
        "            print(\">>>> Best Score Update: {}\".format(best_score))\n",
        "            print(\">>>> Best Params Update: {}\".format(best_params))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"=\" * 30)\n",
        "print(\">>>> Best Score: {}\".format(best_score))\n",
        "print(\">>>> Best Params: {}\".format(best_params))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZF7gAkXt9Otv"
      },
      "outputs": [],
      "source": [
        "# best_params\n",
        "# test set으로 평가\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "lr = LogisticRegression(**best_params, random_state=1353)\n",
        "lr.fit(x_train_tfidf, train_y)\n",
        "pred_y = lr.predict(x_test_tfidf)\n",
        "print(\">>>> accuracy-score: {}\".format(accuracy_score(test_y, pred_y)))\n",
        "print(\">>>> precision-score: {}\".format(precision_score(test_y, pred_y)))\n",
        "print(\">>>> recall-score: {}\".format(recall_score(test_y, pred_y)))\n",
        "print(\">>>> f1-score: {}\".format(f1_score(test_y, pred_y)))\n",
        "\n",
        "confusion_matrix(test_y, pred_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_dId3Dd9Otw"
      },
      "outputs": [],
      "source": [
        "text = '내가 웬만하면 리뷰 안쓰려했는데 이건 좀 선넘은거 아닌가요? 진짜 열받네 ㄹㅇ'\n",
        "text_cv = cv.transform([text])\n",
        "text_tfidf = tfidf_transformer.transform(text_cv)\n",
        "pred = lr.predict(text_tfidf)[0]\n",
        "predict_proba = lr.predict_proba(text_tfidf)[0]\n",
        "print(f\"{round(predict_proba[0], 2)} 확률로 부정 리뷰입니다.\" if pred == 0 else f\"{round(predict_proba[1], 2)} 확률로 긍정 리뷰입니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKGDzwgK9Otw"
      },
      "outputs": [],
      "source": [
        "!pip install seaborn matplotlib wordcloud\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf\n"
      ],
      "metadata": {
        "id": "F1OnM6WyafG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "mpl.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "\n",
        "# Basic statistics of the DataFrame\n",
        "print(reviews.info())\n",
        "\n",
        "# Distribution of Ratings\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x='rating', data=reviews)\n",
        "plt.title('Distribution of Ratings')\n",
        "plt.show()\n",
        "\n",
        "# # Word Cloud for Positive and Negative Reviews\n",
        "# positive_reviews = ' '.join(reviews[reviews['sentiment'] == 1]['content'])\n",
        "# negative_reviews = ' '.join(reviews[reviews['sentiment'] == 0]['content'])\n",
        "\n",
        "# # Word Cloud for Positive Reviews\n",
        "# plt.figure(figsize=(12, 6))\n",
        "# wordcloud_positive = WordCloud(width=800, height=400, background_color='white').generate(positive_reviews)\n",
        "# plt.imshow(wordcloud_positive, interpolation='bilinear')\n",
        "# plt.axis('off')\n",
        "# plt.title('Word Cloud for Positive Reviews')\n",
        "# plt.show()\n",
        "\n",
        "# # Word Cloud for Negative Reviews\n",
        "# plt.figure(figsize=(12, 6))\n",
        "# wordcloud_negative = WordCloud(width=800, height=400, background_color='white').generate(negative_reviews)\n",
        "# plt.imshow(wordcloud_negative, interpolation='bilinear')\n",
        "# plt.axis('off')\n",
        "# plt.title('Word Cloud for Negative Reviews')\n",
        "# plt.show()\n",
        "\n",
        "# Histogram of Review Lengths\n",
        "reviews['review_length'] = reviews['content'].apply(len)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(reviews['review_length'], bins=50, kde=True)\n",
        "plt.title('Distribution of Review Lengths')\n",
        "plt.xlabel('Review Length')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WGahyiZHG661"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}